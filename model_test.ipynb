{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e90a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, yaml\n",
    "import numpy as np\n",
    "from cnn_models import ConvUNet\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.activation import ReLU\n",
    "from torch import cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a787d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interpolate(nn.Module):\n",
    "    def __init__(self, size, mode):\n",
    "        super(Interpolate, self).__init__()\n",
    "        self.interp = nn.functional.interpolate\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.interp(x, size=self.size, mode=self.mode, align_corners=False)\n",
    "        return x\n",
    "\n",
    "class ConvUNetBis(nn.Module):\n",
    "    def __init__(self, input_size, channels_init=16):\n",
    "        super(ConvUNetBis, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.channels_init = channels_init\n",
    "\n",
    "        # encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=channels_init, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.inte1 = nn.Sequential(\n",
    "          Interpolate(size=input_size//16, mode='bilinear'),\n",
    "        )\n",
    "\n",
    "        self.enc2 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=channels_init, out_channels=channels_init*2, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "        )\n",
    "        self.inte2 = nn.Sequential(\n",
    "          Interpolate(size=input_size//32, mode='bilinear'),\n",
    "        )\n",
    "        \n",
    "        self.enc3 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=channels_init*2, out_channels=channels_init*4, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "        )\n",
    "        self.inte3 = nn.Sequential(\n",
    "          Interpolate(size=input_size//64, mode='bilinear'),\n",
    "        )\n",
    "        \n",
    "\n",
    "        # linear layer internal\n",
    "        self.lin1 = nn.Sequential(\n",
    "            nn.Linear(in_features=(channels_init*4)*((input_size//64)**2), out_features=(channels_init*4)*((input_size//64)**2), bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # decoder \n",
    "        self.intd1 = nn.Sequential(\n",
    "          Interpolate(size=input_size//32, mode='bilinear')\n",
    "        )\n",
    "        self.dec1 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=2*channels_init*4, out_channels=channels_init*2, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.intd2 = nn.Sequential(\n",
    "          Interpolate(size=input_size//16, mode='bilinear')\n",
    "        )\n",
    "        self.dec2 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=2*channels_init*2, out_channels=channels_init, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.intd3 = nn.Sequential(\n",
    "          Interpolate(size=input_size, mode='bilinear')\n",
    "        )\n",
    "        self.dec3 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=2*channels_init, out_channels=3, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.dec4 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=3, out_channels=20, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def compute_next_size(self, dimension, kernel, padding=0, stride=1):\n",
    "        return int((dimension + 2*padding - kernel) / stride + 1)\n",
    "\n",
    "    def forward(self, x_input):\n",
    "        # encoding\n",
    "        x_enc1 = self.enc1(x_input)\n",
    "        x = self.inte1(x_enc1)\n",
    "        x_enc2 = self.enc2(x)\n",
    "        x = self.inte2(x_enc2)\n",
    "        x_enc3 = self.enc3(x)\n",
    "        x = self.inte3(x_enc3)\n",
    "        \n",
    "        # latent space operation\n",
    "        x = self.lin1(x.view(-1, self.channels_init*4*((self.input_size//64)**2)))\n",
    "        \n",
    "        # decoder\n",
    "        x = self.intd1(x.view(-1, self.channels_init*4, self.input_size//64, self.input_size//64))\n",
    "        x = self.dec1(cat([x_enc3, x], dim=1))\n",
    "        x = self.intd2(x)\n",
    "        x = self.dec2(cat([x_enc2, x], dim=1))\n",
    "        x = self.intd3(x)\n",
    "        x = self.dec3(cat([x_enc1, x], dim=1))\n",
    "        reconstruction = self.dec4(x)\n",
    "        return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f1178dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallLinear(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SmallLinear, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(22, 15)\n",
    "        self.lin2 = torch.nn.Linear(15, 10)\n",
    "        self.lin3 = torch.nn.Linear(10, 3)\n",
    "        self.activation = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "\n",
    "smallLinear = SmallLinear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f1030",
   "metadata": {},
   "source": [
    "### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9808d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# setting device and data types\n",
    "dtype = torch.float32 \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b9a9cd",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044476e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model config\n",
    "with open('training_config.yml') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "# image size\n",
    "reshape_size = config['reshape_size']\n",
    "scale_factor = config['scale_factor']\n",
    "file_name = 'channel_x1_256_y1_512_z1_256_step2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba1290",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cf86c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "x_all = np.load('data/' + file_name + '/xs.npy')\n",
    "y_all = np.load('data/' + file_name + '/ys.npy')\n",
    "u_all = np.load('data/' + file_name + '/us.npy')\n",
    "v_all = np.load('data/' + file_name + '/vs.npy')\n",
    "p_all = np.load('data/' + file_name + '/ps.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e49ea1",
   "metadata": {},
   "source": [
    "### Create segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a5efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation maps\n",
    "seg_map_all = 2*np.ones_like(x_all)\n",
    "seg_map_all[:, 0, :] = 1\n",
    "seg_map_all[:, -1, :] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9e6f3a",
   "metadata": {},
   "source": [
    "### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5580e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = int(0.8*len(x_all))\n",
    "\n",
    "x, y, seg_map = [\n",
    "    torch.tensor(arr[:len_train, :, :], requires_grad=True).unsqueeze(-1).permute((0, 3, 1, 2)) for arr in [x_all, y_all, seg_map_all]\n",
    "]\n",
    "\n",
    "u, v, p = [\n",
    "    torch.tensor(arr[:len_train, :, :], requires_grad=True).unsqueeze(-1) for arr in [u_all, v_all, p_all]\n",
    "]\n",
    "\n",
    "x_val, y_val, seg_map_val = [\n",
    "    torch.tensor(arr[len_train:, :, :], requires_grad=False).unsqueeze(-1).permute((0, 3, 1, 2)) for arr in [x_all, y_all, seg_map_all]\n",
    "]\n",
    "\n",
    "u_val, v_val, p_val = [\n",
    "    torch.tensor(arr[len_train:, :, :], requires_grad=False).unsqueeze(-1) for arr in [u_all, v_all, p_all]\n",
    "]\n",
    "\n",
    "# data\n",
    "train_data = torch.cat([u, v, p], axis=-1)\n",
    "train_data = train_data.permute((0, 3, 1, 2))\n",
    "val_data = torch.cat([u_val, v_val, p_val], axis=-1)\n",
    "val_data = val_data.permute((0, 3, 1, 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03c72d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom dataset\n",
    "class ChannelFlowFull(Dataset):\n",
    "    def __init__(self, x, y, vels, seg_map):\n",
    "        super(ChannelFlowFull, self).__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.seg_map = seg_map\n",
    "        self.vels = vels\n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx], self.vels[idx], self.seg_map[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68fff7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "train_dataset = ChannelFlowFull(x, y, train_data, seg_map)\n",
    "val_dataset = ChannelFlowFull(x_val, y_val, val_data, seg_map_val)\n",
    "\n",
    "# dataloaders\n",
    "batch_size = config['batch_size']\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a67ffae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_sample, y_sample, flow_sample, seg_map_sample in train_dataloader:\n",
    "    x_sample = x_sample.to(device=device, dtype=dtype)\n",
    "    y_sample = y_sample.to(device=device, dtype=dtype)\n",
    "    flow_sample = flow_sample.to(device=device, dtype=dtype) # move to device, e.g. GPU\n",
    "    seg_map_sample = seg_map_sample.to(device=device, dtype=dtype).squeeze()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0153b8d",
   "metadata": {},
   "source": [
    "### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7cc05b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  71039  parameters to train.\n"
     ]
    }
   ],
   "source": [
    "model = ConvUNetBis(input_size=256, channels_init=4)\n",
    "model = model.to(device=device)\n",
    "model.train()\n",
    "print('There are ', sum(p.numel() for p in model.parameters()), ' parameters to train.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6cea2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = list(model.parameters()) + list(smallLinear.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16179588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "optimizer = torch.optim.Adam(all_params, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b2a1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors = model(flow_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9bbea6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors_perm = latent_vectors.permute(0, 2, 3, 1)\n",
    "interior_points = latent_vectors_perm[seg_map_sample==2] # all interior points from the batch\n",
    "boundary_points = latent_vectors_perm[seg_map_sample==1] # all boundary points from the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "73e5b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample_perm = x_sample.permute(0, 2, 3, 1)\n",
    "y_sample_perm = y_sample.permute(0, 2, 3, 1)\n",
    "\n",
    "x_interior_points = x_sample_perm[seg_map_sample==2].view(-1, 1)\n",
    "x_boundary_points = x_sample_perm[seg_map_sample==1].view(-1, 1)\n",
    "y_interior_points = y_sample_perm[seg_map_sample==2].view(-1, 1)\n",
    "y_boundary_points = y_sample_perm[seg_map_sample==1].view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d3ace633",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = torch.cat([x_interior_points, y_interior_points, interior_points], dim=1)\n",
    "inputs = [input_features[..., i:i+1] for i in range(input_features.shape[-1])]\n",
    "x_ = torch.cat(inputs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7f32f686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([520192, 22])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "86d995d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  538  parameters to train.\n"
     ]
    }
   ],
   "source": [
    "print('There are ', sum(p.numel() for p in smallLinear.parameters()), ' parameters to train.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "90938653",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_linear = smallLinear(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c42877f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dudx, dudy = torch.autograd.grad(outputs_linear[:,0], [inputs[0], inputs[1]], grad_outputs=torch.ones_like(outputs_linear[:, 0]).view(-1), retain_graph=True, create_graph=True)\n",
    "d2udx2 = torch.autograd.grad(dudx, inputs[0], grad_outputs=torch.ones_like(dudx), retain_graph=True, create_graph=True)\n",
    "d2udy2 = torch.autograd.grad(dudy, inputs[1], grad_outputs=torch.ones_like(dudy), retain_graph=True, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c56b05ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean((dudx + dudy)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05447217",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bf5e8711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0006, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9331d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ns_clevrer",
   "language": "python",
   "name": "ns_clevrer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
