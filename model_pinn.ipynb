{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting device and data types\n",
    "dtype = torch.float32 \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input channels will be:\n",
    "    - x, x coordinate position.\n",
    "    - y, y coordinate position.\n",
    "    - u, velocity in the x direction.\n",
    "    - v, velocity in the y direction.\n",
    "    - p, pressure field.\n",
    "\n",
    "Output channels, will have three:\n",
    "    - u, velocity in the x direction.\n",
    "    - v, velocity in the y direction.\n",
    "    - p, pressure field.\n",
    "\n",
    "Can I, in a way, add equivariant constraints? Enfore that the model is equivariant.\n",
    "Add padding to allow for the boundary conditions to exist. Also allows for data augmentation, \n",
    "which should prevent overfitting on learning the boundary conditions.\n",
    "\n",
    "Model trained as an autoencoder, with a PDE loss. We expect that the PDE loss contradicts the AE.\n",
    "Maybe, could start with the AE to be noearly convergent, and then add the PDE. PDE alone might fail at\n",
    "performing the auto-encoding overall.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interpolate(nn.Module):\n",
    "    def __init__(self, size, mode):\n",
    "        super(Interpolate, self).__init__()\n",
    "        self.interp = nn.functional.interpolate\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.interp(x, size=self.size, mode=self.mode, align_corners=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.activation import ReLU\n",
    "class ConvAE(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ConvAE, self).__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=5, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            Interpolate(size=input_size//2, mode='bilinear'),\n",
    "        )\n",
    "\n",
    "        self.enc2 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "          Interpolate(size=input_size//8, mode='bilinear'),\n",
    "        )\n",
    "        \n",
    "        self.enc3 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "          Interpolate(size=input_size//16, mode='bilinear'),\n",
    "        )\n",
    "\n",
    "        # decoder \n",
    "        self.dec1 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "          Interpolate(size=input_size//8, mode='bilinear'),\n",
    "        )\n",
    "        self.dec2 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "          Interpolate(size=input_size//2, mode='bilinear'),\n",
    "        )\n",
    "        self.dec3 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=16, out_channels=5, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "          Interpolate(size=input_size, mode='bilinear'),\n",
    "        )\n",
    "        self.dec4 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=5, out_channels=3, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "    \n",
    "    def compute_next_size(self, dimension, kernel, padding=0, stride=1):\n",
    "        return int((dimension + 2*padding - kernel) / stride + 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x = self.enc1(x)\n",
    "        x = self.enc2(x)\n",
    "        x = self.enc3(x)\n",
    "        \n",
    "        # decoding\n",
    "        x = self.dec1(x)\n",
    "        x = self.dec2(x)\n",
    "        x = self.dec3(x)\n",
    "        reconstruction = self.dec4(x)\n",
    "        return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function? will have to think about it :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((5, 5), requires_grad=True)\n",
    "y = torch.randn((5, 5), requires_grad=True)\n",
    "u = torch.randn((5, 5), requires_grad=True)\n",
    "v = torch.randn((5, 5), requires_grad=True)\n",
    "p = torch.randn((5, 5), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "upred = (x**2*y+y**2)*u\n",
    "vpred = (y*x)**2*v\n",
    "ppred = x*v + y*u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dudx, dudy = torch.autograd.grad(upred, [x, y], grad_outputs=torch.ones(upred.shape), retain_graph=True, create_graph=True)\n",
    "dvdx, dvdy = torch.autograd.grad(vpred, [x, y], grad_outputs=torch.ones(upred.shape), retain_graph=True, create_graph=True)\n",
    "dpdx, dpdy = torch.autograd.grad(upred, [x, y], grad_outputs=torch.ones(upred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2udx2 = torch.autograd.grad(dudx, x, grad_outputs=torch.ones(upred.shape), retain_graph=True,)[0]\n",
    "d2udy2 = torch.autograd.grad(dudy, y, grad_outputs=torch.ones(upred.shape))[0]\n",
    "d2vdx2 = torch.autograd.grad(dvdx, x, grad_outputs=torch.ones(upred.shape), retain_graph=True,)[0]\n",
    "d2vdy2 = torch.autograd.grad(dvdy, y, grad_outputs=torch.ones(upred.shape))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pde_loss, each navier stokes term difference squared!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('3.9.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc99516081da5f0fa2e25eb64409361896b1dbdaea98904a47dda2227a1d4410"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
