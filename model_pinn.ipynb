{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting device and data types\n",
    "dtype = torch.float32 \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInput channels will be:\\n    - x, x coordinate position.\\n    - y, y coordinate position.\\n    - u, velocity in the x direction.\\n    - v, velocity in the y direction.\\n    - p, pressure field.\\n\\nOutput channels, will have three:\\n    - u, velocity in the x direction.\\n    - v, velocity in the y direction.\\n    - p, pressure field.\\n\\nCan I, in a way, add equivariant constraints? Enfore that the model is equivariant.\\nAdd padding to allow for the boundary conditions to exist. Also allows for data augmentation, \\nwhich should prevent overfitting on learning the boundary conditions.\\n\\nModel trained as an autoencoder, with a PDE loss. We expect that the PDE loss contradicts the AE.\\nMaybe, could start with the AE to be noearly convergent, and then add the PDE. PDE alone might fail at\\nperforming the auto-encoding overall.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Input channels will be:\n",
    "    - x, x coordinate position.\n",
    "    - y, y coordinate position.\n",
    "    - u, velocity in the x direction.\n",
    "    - v, velocity in the y direction.\n",
    "    - p, pressure field.\n",
    "\n",
    "Output channels, will have three:\n",
    "    - u, velocity in the x direction.\n",
    "    - v, velocity in the y direction.\n",
    "    - p, pressure field.\n",
    "\n",
    "Can I, in a way, add equivariant constraints? Enfore that the model is equivariant.\n",
    "Add padding to allow for the boundary conditions to exist. Also allows for data augmentation, \n",
    "which should prevent overfitting on learning the boundary conditions.\n",
    "\n",
    "Model trained as an autoencoder, with a PDE loss. We expect that the PDE loss contradicts the AE.\n",
    "Maybe, could start with the AE to be noearly convergent, and then add the PDE. PDE alone might fail at\n",
    "performing the auto-encoding overall.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interpolate(nn.Module):\n",
    "    def __init__(self, size, mode):\n",
    "        super(Interpolate, self).__init__()\n",
    "        self.interp = nn.functional.interpolate\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.interp(x, size=self.size, mode=self.mode, align_corners=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.activation import ReLU\n",
    "class ConvAE(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ConvAE, self).__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=5, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            Interpolate(size=input_size//2, mode='bilinear'),\n",
    "        )\n",
    "\n",
    "        self.enc2 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "          Interpolate(size=input_size//8, mode='bilinear'),\n",
    "        )\n",
    "        \n",
    "        self.enc3 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "          Interpolate(size=input_size//16, mode='bilinear'),\n",
    "        )\n",
    "\n",
    "        # decoder \n",
    "        self.dec1 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "          Interpolate(size=input_size//8, mode='bilinear'),\n",
    "        )\n",
    "        self.dec2 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "          Interpolate(size=input_size//2, mode='bilinear'),\n",
    "        )\n",
    "        self.dec3 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=16, out_channels=5, kernel_size=3, stride=1, padding=1),\n",
    "          nn.ReLU(),\n",
    "          Interpolate(size=input_size, mode='bilinear'),\n",
    "        )\n",
    "        self.dec4 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=5, out_channels=3, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "    \n",
    "    def compute_next_size(self, dimension, kernel, padding=0, stride=1):\n",
    "        return int((dimension + 2*padding - kernel) / stride + 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x = self.enc1(x)\n",
    "        x = self.enc2(x)\n",
    "        x = self.enc3(x)\n",
    "        \n",
    "        # decoding\n",
    "        x = self.dec1(x)\n",
    "        x = self.dec2(x)\n",
    "        x = self.dec3(x)\n",
    "        reconstruction = self.dec4(x)\n",
    "        return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=320\n",
    "model = ConvAE(input_size=input_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function? will have to think about it :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((10, input_size, input_size, 1), requires_grad=True)\n",
    "y = torch.randn((10, input_size, input_size, 1), requires_grad=True)\n",
    "u = torch.randn((10, input_size, input_size, 1), requires_grad=True)\n",
    "v = torch.randn((10, input_size, input_size, 1), requires_grad=True)\n",
    "p = torch.randn((10, input_size, input_size, 1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 320, 320])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_input = torch.cat([x, y, u, v, p], axis=-1)\n",
    "flow_input = flow_input.permute((0, 3, 1, 2))\n",
    "flow_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 320, 320])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "flow_output = model(flow_input)\n",
    "flow_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upred = (x**2*y+y**2)*u\n",
    "# vpred = (y*x)**2*v\n",
    "# ppred = x*v + y*u\n",
    "# flow_output = torch.cat((upred, vpred, ppred), axis=-1)\n",
    "# flow_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "upred = flow_output[:, 0]\n",
    "vpred = flow_output[:, 1]\n",
    "ppred = flow_output[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_functions import PDELoss\n",
    "pde_loss_function = PDELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g1/y2qxmp357nv407mqvk_ryty00000gn/T/ipykernel_25998/2783664486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpde_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpde_loss_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 1 with size 3"
     ]
    }
   ],
   "source": [
    "pde_loss = pde_loss_function.compute_loss(flow_input[:, 0], flow_input[:, 1], flow_output[:, 0], flow_output[:, 1], flow_output[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dudx, dudy = torch.autograd.grad(upred, [x, y], grad_outputs=torch.ones(upred.shape), retain_graph=True, create_graph=True)\n",
    "dvdx, dvdy = torch.autograd.grad(vpred, [x, y], grad_outputs=torch.ones(vpred.shape), retain_graph=True, create_graph=True)\n",
    "dpdx, dpdy = torch.autograd.grad(ppred, [x, y], grad_outputs=torch.ones(ppred.shape), retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 320, 320, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dudx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2udx2 = torch.autograd.grad(dudx.squeeze(), x, grad_outputs=torch.ones(dudx.squeeze().shape), retain_graph=True)[0]\n",
    "d2udy2 = torch.autograd.grad(dudy.squeeze(), y, grad_outputs=torch.ones(dudy.squeeze().shape), retain_graph=True)[0]\n",
    "d2vdx2 = torch.autograd.grad(dvdx.squeeze(), x, grad_outputs=torch.ones(dvdx.squeeze().shape), retain_graph=True)[0]\n",
    "d2vdy2 = torch.autograd.grad(dvdy.squeeze(), y, grad_outputs=torch.ones(dvdy.squeeze().shape), retain_graph=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pde_loss, each navier stokes term difference squared!\n",
    "ae_loss_function = nn.MSELoss(reduction='mean')\n",
    "ae_loss = ae_loss_function(flow_input[:, 2:], flow_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" assume steady state Navier-Stokes...? No, must have a time component somewhere. I remeber thinking about this.\\nWhere am I suppose to put this time component? add it in the latent space? with the Reynold's number?\\nOr with the density, the viscosity?\\nWell, if you non-dmiensionalise, you just need the Re, that's the point, but you also need to non-dimensinoalise\\nthe distance, etc... \\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' assume steady state Navier-Stokes...? No, must have a time component somewhere. I remeber thinking about this.\n",
    "Where am I suppose to put this time component? add it in the latent space? with the Reynold's number?\n",
    "Or with the density, the viscosity?\n",
    "Well, if you non-dmiensionalise, you just need the Re, that's the point, but you also need to non-dimensinoalise\n",
    "the distance, etc... \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 1\n",
    "mu = 1\n",
    "beta = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 320, 320]), torch.Size([10, 320, 320, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upred.shape, d2udx2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuity_error = torch.sum((dudx.squeeze() + dvdy.squeeze())**2)\n",
    "xmomentum_error = torch.sum((rho*(upred*dudx.squeeze() + vpred*dudy.squeeze()) + dpdx.squeeze() - mu*(d2udx2.squeeze() + d2udy2.squeeze()))**2)\n",
    "ymomentum_error = torch.sum((rho*(upred*dvdx.squeeze() + vpred*dvdy.squeeze()) + dpdy.squeeze() - mu*(d2vdx2.squeeze() + d2vdy2.squeeze()))**2)\n",
    "loss = beta*ae_loss + (1-beta)*(continuity_error + xmomentum_error + ymomentum_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.9337444, dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('3.9.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc99516081da5f0fa2e25eb64409361896b1dbdaea98904a47dda2227a1d4410"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
